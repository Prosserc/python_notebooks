{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5bed5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "app_dir = r'D:\\code\\projects\\IGI.ML.Server'\n",
    "sys.path.append(app_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1109da07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_app.modelling.session_register import active_sessions\n",
    "from ml_app.modelling.entities.model import ModelOptions, ModelClass, ModelType\n",
    "from ml_app.modelling.entities.option_types import PreprocessingOptions, TrainingOptions, NullReplacement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd05052e",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "1. Create a model (for each model type using a large training file)\n",
    "2. Look at raw object size vs str encoded size using current code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec46b0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Created session with key 0dd45fda-7c73-48bf-8ee6-06992d40cf52\n"
     ]
    }
   ],
   "source": [
    "fpath = 'non_linear_darcy_weisbach.csv'\n",
    "session = active_sessions.create_session_from_filepath(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fe6aea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build options\n",
    "preproc = PreprocessingOptions(\n",
    "    standardise=True, normalise=False, \n",
    "    null_replacement=NullReplacement.auto)\n",
    "training = TrainingOptions(training_split=0.8, random_seed=42)\n",
    "\n",
    "def create_model_options(model_type: ModelType):\n",
    "    \"\"\"create model options with same input except for model type\"\"\"\n",
    "    return ModelOptions(\n",
    "        preproc=preproc,\n",
    "        training=training,\n",
    "        result_column='Pressure Drop (Pascals)',\n",
    "        model_class=ModelClass.Regression,\n",
    "        model_type=model_type)\n",
    "\n",
    "lr_options = create_model_options(ModelType.LinearRegression)\n",
    "gbr_options = create_model_options(ModelType.GradientBoostingRegressor)\n",
    "gpr_options = create_model_options(ModelType.GaussianProcessRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14205920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train models\n",
    "lr_model = session.build_experiment(lr_options).model\n",
    "gbr_model = session.build_experiment(gbr_options).model\n",
    "gpr_model = session.build_experiment(gpr_options).model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4831851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create serialsied model strings (with current process)\n",
    "from ml_app.dtos.serialise.pickler import get_pickled_model_string\n",
    "\n",
    "cols = session.data.columns\n",
    "lr_str = get_pickled_model_string(model=lr_model, col_info=cols)\n",
    "gbr_str = get_pickled_model_string(model=gbr_model, col_info=cols)\n",
    "gpr_str = get_pickled_model_string(model=gpr_model, col_info=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2632fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "nowish = datetime.now().strftime(\"%y%m%d_%H%M\")\n",
    "log_file = f\"compression_tests_10k_6_cols_{nowish}.csv\"\n",
    "log_counter = 0\n",
    "\n",
    "# create log file to capture sizes etc\n",
    "def append_log(test_desc, lr_bytes, gbr_bytes, gpr_bytes):\n",
    "    global log_counter\n",
    "    if log_counter == 0:\n",
    "        # write headers\n",
    "        with open(log_file, 'w') as f:\n",
    "            desc = \"Test Description\"\n",
    "            f.write(f\"{desc: <46}\\tLR (MB)  \\t GBR (MB)\\t GPR (MB)\\n\")\n",
    "    to_mb = lambda by: round(by/1024/1024, 3)\n",
    "    with open(log_file, 'a') as f:\n",
    "        f.write(f\"{test_desc: <46}\\t{to_mb(lr_bytes): >9.2f}\\t\"\n",
    "                f\"{to_mb(gbr_bytes): >9.2f}\\t{to_mb(gpr_bytes): >9.2f}\\n\")\n",
    "    log_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2217955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write object size\n",
    "import sys, pickle\n",
    "sizes = [sys.getsizeof(pickle.dumps(m)) \n",
    "        for m in (lr_model, gbr_model, gpr_model)]\n",
    "append_log('Model object just pickled (no further changes)', *sizes)\n",
    "\n",
    "# write size of serialised string\n",
    "str_sizes = [sys.getsizeof(s) for s in (lr_str, gbr_str, gpr_str)]\n",
    "append_log('Serialised (incl pickle, dto conv, b64 & hmac)', *str_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213f5ea3",
   "metadata": {},
   "source": [
    "# Attempt 1\n",
    "\n",
    "Try with zlib and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0936dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zlib, codecs\n",
    "\n",
    "compressed_bytes = [zlib.compress(x.encode()) \n",
    "                    for x in (lr_str, gbr_str, gpr_str)]\n",
    "compressed_str = [codecs.encode(c, \"base64\").decode() for c in compressed_bytes]\n",
    "comp_str_sizes = map(sys.getsizeof, compressed_str)\n",
    "append_log('Serialised (as above +zlib default level -b64)', *comp_str_sizes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae0aaeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try zlib level 9\n",
    "compressed_bytes = [zlib.compress(x.encode(), level=9) \n",
    "                    for x in (lr_str, gbr_str, gpr_str)]\n",
    "compressed_str = [codecs.encode(c, \"base64\").decode() for c in compressed_bytes]\n",
    "comp_str_sizes = map(sys.getsizeof, compressed_str)\n",
    "append_log('Serialised (as above +zlib level 9 -b64)', *comp_str_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fe51c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_app",
   "language": "python",
   "name": "ml_app"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
